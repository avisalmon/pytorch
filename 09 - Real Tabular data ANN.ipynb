{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb9b371-6c8d-4cb5-916e-03552d998e38",
   "metadata": {},
   "source": [
    "## Working with tabular data\n",
    "\n",
    "Here we're working with tabular data (spreadsheets, SQL tables, etc.) with columns of values that may or may not be relevant. As it happens, neural networks can learn to make connections we probably wouldn't have developed on our own. However, to do this we have to handle categorical values separately from continuous ones. Make sure to watch the theory lectures! You'll want to be comfortable with:\n",
    "* continuous vs. categorical values\n",
    "* embeddings\n",
    "* batch normalization\n",
    "* dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b9b890-b9bd-4868-b01f-6d20d585afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a61b53c-2f42-455f-8e48-1b9c1c9e29db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/NYCTaxiFares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05941a3f-a558-44cb-9325-e70be921e602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98c8d7-5ecf-47c2-a501-657cffe98f51",
   "metadata": {},
   "source": [
    "## Calculate the distance traveled\n",
    "The <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> calculates the distance on a sphere between two sets of GPS coordinates.<br>\n",
    "Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{split} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{split}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19f084d-46af-494e-9f8e-332d78db843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    print(phi1.shape)\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ac30cc-b404-4a25-b6f9-7bd055a13c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb85957-a04f-47c9-9414-405d76307b22",
   "metadata": {},
   "source": [
    "## Add a datetime column and derive useful statistics\n",
    "By creating a datetime object, we can extract information like \"day of the week\", \"am vs. pm\" etc.\n",
    "Note that the data was saved in UTC time. Our data falls in April of 2010 which occurred during Daylight Savings Time in New York. For that reason, we'll make an adjustment to EDT using UTC-4 (subtracting four hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abad72b-5f62-4dcf-877c-c1967cdbae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7c2196-a98a-4b82-9a0b-7dda8715e115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-11 00:00:10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fcaff4-d706-457f-9da3-3d2c3149ed3b",
   "metadata": {},
   "source": [
    "## Separate categorical from continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9d52cf-95b6-487e-b641-d870c6316aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337795da-dbcc-4580-ba2a-42752100b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']  # this column contains the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38529abc-407b-4ef3-bd28-1f586f803f47",
   "metadata": {},
   "source": [
    "## Categorify\n",
    "Pandas offers a <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html'><strong>category dtype</strong></a> for converting categorical values to numerical codes. A dataset containing months of the year will be assigned 12 codes, one for each month. These will usually be the integers 0 to 11. Pandas replaces the column values with codes, and retains an index list of category values. In the steps ahead we'll call the categorical values \"names\" and the encodings \"codes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc638bf5-97e7-49cc-b49b-494c40aa1310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our three categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0818f5dd-9712-432e-b963-3a2118a0f165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                       category\n",
       "AMorPM                     category\n",
       "Weekday                    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c7f48d-ae1c-48b5-b5db-df4052dfd9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int32): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911924a4-cb76-4022-bef3-a1ec98f830cc",
   "metadata": {},
   "source": [
    "Here our categorical names are the integers 0 through 23, for a total of 24 unique categories. These values <em>also</em> correspond to the codes assigned to each name.\n",
    "\n",
    "We can access the category names with <tt>Series.cat.categories</tt> or just the codes with <tt>Series.cat.codes</tt>. This will make more sense if we look at <tt>df['AMorPM']</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c86655e-e2c7-4b0c-b615-4ca9172059d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    am\n",
       "1    am\n",
       "2    am\n",
       "3    pm\n",
       "4    pm\n",
       "Name: AMorPM, dtype: category\n",
       "Categories (2, object): ['am', 'pm']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f494273-4837-4b34-9f20-0fd6421effde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc913c30-7a28-4331-a210-d0a4a4821ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head().cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf5c127-8a14-4af7-aedb-394840bd6ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01ced6b5-02d5-44ec-8b31-85c5e0af967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head().cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89746a6-3705-46a6-83f5-f81e0723e534",
   "metadata": {},
   "source": [
    "NOTE: NaN values in categorical data are assigned a code of -1. We don't have any in this particular dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75ef3d-16f3-4e55-b6ca-c0b07ba210be",
   "metadata": {},
   "source": [
    "Now we want to combine the three categorical columns into one input array using numpy.stack We don't want the Series index, just the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76e6c1b3-4f79-4e79-8144-4cc51765f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       [17,  1,  3],\n",
       "       [22,  1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr, ampm, wkdy], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8c0b3-b712-4794-a23c-30076f8a7ee2",
   "metadata": {},
   "source": [
    "NOTE: This can be done in one line of code using a list comprehension:\n",
    "cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)\n",
    "Don't worry about the dtype for now, we can make it int64 when we convert it to a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3754c-8063-45c4-8f93-192049ab5e36",
   "metadata": {},
   "source": [
    "## Convert numpy arrays to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94f5f1bd-2af6-4896-86f1-2ad8cd541a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3],\n",
       "        [22,  1,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to a tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64) \n",
    "# this syntax is ok, since the source data is an array, not an existing tensor\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd1c9c-150f-42c4-9e5a-1d97cf289a19",
   "metadata": {},
   "source": [
    "We can feed all of our continuous variables into the model as a tensor. Note that we're not normalizing the values here; we'll let the model perform this step.\n",
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> We have to store <tt>conts</tt> and <tt>y</tt> as Float (float32) tensors, not Double (float64) in order for batch normalization to work properly.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c3d6f30-b724-4eae-8a25-91d6c9f9a162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert continuous variables to a tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54a6193d-e235-47e1-93d7-6d20634fa10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c6f8089-2216-4a27-83a2-85e0d0fa1084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5000],\n",
       "        [ 6.9000],\n",
       "        [10.1000],\n",
       "        [ 8.9000],\n",
       "        [19.7000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to a tensor\n",
    "y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "619280eb-de78-4c96-ab59-7b7c190a7b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b3d57fd-a014-4e91-8a46-f94bc083e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd9a4dbe-cfb9-4b51-b68d-2bf453cb844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e225ed-a8a2-428e-aa5d-b88eda718f48",
   "metadata": {},
   "source": [
    "## Set an embedding size\n",
    "The rule of thumb for determining the embedding size is to divide the number of unique entries in each column by 2, but not to exceed 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49eb6903-daad-4ac4-add9-052680f8f727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360a412-4937-4d0c-91f0-c2ce3454dccb",
   "metadata": {},
   "source": [
    "## Define a TabularModel\n",
    "This somewhat follows the <a href='https://docs.fast.ai/tabular.models.html'>fast.ai library</a> The goal is to define a model based on the number of continuous columns (given by <tt>conts.shape[1]</tt>) plus the number of categorical columns and their embeddings (given by <tt>len(emb_szs)</tt> and <tt>emb_szs</tt> respectively). The output would either be a regression (a single float value), or a classification (a group of bins and their softmax values). For this exercise our output will be a single regression value. Note that we'll assume our data contains both categorical and continuous data. You can add boolean parameters to your own model class to handle a variety of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd67c5b-4a37-4f19-a3ef-d67814d2c164",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take. See below for more detailed illustrations of the steps.</strong><br>\n",
    "\n",
    "1. Extend the base Module class, set up the following parameters:\n",
    "   * <tt>emb_szs: </tt>list of tuples: each categorical variable size is paired with an embedding size\n",
    "   * <tt>n_cont:  </tt>int: number of continuous variables\n",
    "   * <tt>out_sz:  </tt>int: output size\n",
    "   * <tt>layers:  </tt>list of ints: layer sizes\n",
    "   * <tt>p:       </tt>float: dropout probability for each layer (for simplicity we'll use the same value throughout)\n",
    "   \n",
    "<tt><font color=black>class TabularModel(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self, emb_szs, n_cont, out_sz, layers, p=0.5):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the embedded layers with <a href='https://pytorch.org/docs/stable/nn.html#modulelist'><tt><strong>torch.nn.ModuleList()</strong></tt></a> and <a href='https://pytorch.org/docs/stable/nn.html#embedding'><tt><strong>torch.nn.Embedding()</strong></tt></a><br>Categorical data will be filtered through these Embeddings in the forward section.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])</font></tt><br><br>\n",
    "3. Set up a dropout function for the embeddings with <a href='https://pytorch.org/docs/stable/nn.html#dropout'><tt><strong>torch.nn.Dropout()</strong></tt></a> The default p-value=0.5<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.emb_drop = nn.Dropout(emb_drop)</font></tt><br><br>\n",
    "4. Set up a normalization function for the continuous variables with <a href='https://pytorch.org/docs/stable/nn.html#batchnorm1d'><tt><strong>torch.nn.BatchNorm1d()</strong></tt></a><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)</font></tt><br><br>\n",
    "5. Set up a sequence of neural network layers where each level includes a Linear function, an activation function (we'll use <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong>ReLU</strong></a>), a normalization step, and a dropout layer. We'll combine the list of layers with <a href='https://pytorch.org/docs/stable/nn.html#sequential'><tt><strong>torch.nn.Sequential()</strong></tt></a><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;layerlist = []<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;n_emb = sum((nf for ni,nf in emb_szs))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;n_in = n_emb + n_cont<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i in layers:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(n_in,i)) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.ReLU(inplace=True))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.BatchNorm1d(i))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Dropout(p))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_in = i<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(layers[-1],out_sz))<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;self.layers = nn.Sequential(*layerlist)</font></tt><br><br>\n",
    "6. Define the forward method. Preprocess the embeddings and normalize the continuous variables before passing them through the layers.<br>Use <a href='https://pytorch.org/docs/stable/torch.html#torch.cat'><tt><strong>torch.cat()</strong></tt></a> to combine multiple tensors into one.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;def forward(self, x_cat, x_cont):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;embeddings = []<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i,e in enumerate(self.embeds):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;embeddings.append(e(x_cat[:,i]))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat(embeddings, 1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = self.emb_drop(x)<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x_cont = self.bn_cont(x_cont)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat([x, x_cont], 1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = self.layers(x)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return x</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d8fa2-0281-4d87-b3a8-c3ea05478bfb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the embeddings steps</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ff010aa-0a06-42a2-93df-5198dcb8712b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our source data\n",
    "catz = cats[:4]\n",
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6498dfd-8db1-439d-b18d-a8d0579e4c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30cd2c4f-6f46-4da9-b968-b1097f570141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is passed in when the model is instantiated\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74a8ab42-4a0a-4098-b248-244df63af1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is assigned inside the __init__() method\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f57e75df-6f76-4f86-9431-734eefe42624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(selfembeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9eab810-2378-49c1-8bc7-6c5ebe97715b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.1348, -1.4565, -0.3564, -0.7378, -1.2429, -1.1614,  0.0657,  0.6745,\n",
       "          -0.9815,  2.3100,  0.0367,  1.6586],\n",
       "         [-1.0345,  0.9962, -0.2958,  0.5841, -0.4239, -1.6378, -0.3318,  1.1930,\n",
       "          -0.7024,  0.2956, -1.5408, -1.1221],\n",
       "         [-2.3983, -1.5751,  0.0388,  1.4689,  0.0672, -0.5417, -1.4544,  0.3146,\n",
       "          -0.1117, -1.5624,  0.0180, -1.1375],\n",
       "         [ 0.9610, -0.2312, -0.3516, -0.5223,  0.5717,  0.1537, -0.1655,  1.1013,\n",
       "          -0.5210,  0.9435,  0.5082,  1.0151]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[1.0648],\n",
       "         [1.0648],\n",
       "         [1.0648],\n",
       "         [0.4119]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.3912, -1.9218, -1.8300,  0.2453],\n",
       "         [-1.7981, -0.7479, -0.2457,  0.9491],\n",
       "         [-1.7981, -0.7479, -0.2457,  0.9491],\n",
       "         [-0.1379,  0.7043,  1.2793, -0.4707]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This happens inside the forward() method\n",
    "embeddingz = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))\n",
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c381b2ae-03e1-4b3b-9148-b57f6ce907ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1348, -1.4565, -0.3564, -0.7378, -1.2429, -1.1614,  0.0657,  0.6745,\n",
       "         -0.9815,  2.3100,  0.0367,  1.6586,  1.0648,  0.3912, -1.9218, -1.8300,\n",
       "          0.2453],\n",
       "        [-1.0345,  0.9962, -0.2958,  0.5841, -0.4239, -1.6378, -0.3318,  1.1930,\n",
       "         -0.7024,  0.2956, -1.5408, -1.1221,  1.0648, -1.7981, -0.7479, -0.2457,\n",
       "          0.9491],\n",
       "        [-2.3983, -1.5751,  0.0388,  1.4689,  0.0672, -0.5417, -1.4544,  0.3146,\n",
       "         -0.1117, -1.5624,  0.0180, -1.1375,  1.0648, -1.7981, -0.7479, -0.2457,\n",
       "          0.9491],\n",
       "        [ 0.9610, -0.2312, -0.3516, -0.5223,  0.5717,  0.1537, -0.1655,  1.1013,\n",
       "         -0.5210,  0.9435,  0.5082,  1.0151,  0.4119, -0.1379,  0.7043,  1.2793,\n",
       "         -0.4707]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We concatenate the embedding sections (12,1,4) into one (17)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba205503-2965-441c-a285-2a77013d66e7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>This is how the categorical embeddings are passed into the layers.</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f75902d3-160c-421a-980b-d7338406f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44e1da73-fd8a-4988-9384-8417798949b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbc57b65-8674-42b4-ab50-0d6e735917b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be94d12-7ca3-42b5-9155-ce928cd46246",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer\n",
    "PyTorch does not offer a built-in <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE Loss</a> function, and it would be nice to see this in place of MSE.<br>\n",
    "For this reason, we'll simply apply the <tt>torch.sqrt()</tt> function to the output of MSELoss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c802b9ae-2906-4fa4-be4c-011327b3364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # we'll convert this to RMSE later\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b99be47-eedd-4833-acd9-0ac019df38c1",
   "metadata": {},
   "source": [
    "## Perform train/test splits\n",
    "At this point our batch size is the entire dataset of 120,000 records. This will take a long time to train, so you might consider reducing this. We'll use 60,000. Recall that our tensors are already randomly shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04ffd202-0bfc-4edf-a275-26b924762ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1ca6ae2-3bc2-45c6-9369-e137da39d41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29312a28-7070-4625-9497-48954da175fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3891b-6d0e-42a5-8e97-e38e6739526c",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Expect this to take 30 minutes or more! We've added code to tell us the duration at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ad3d002-d8c5-441b-bb7c-34331adfbfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.56901073\n",
      "epoch:  26  loss: 10.90574360\n",
      "epoch:  51  loss: 10.22923946\n",
      "epoch:  76  loss: 9.74728203\n",
      "epoch: 101  loss: 9.19752884\n",
      "epoch: 126  loss: 8.42101860\n",
      "epoch: 151  loss: 7.40510988\n",
      "epoch: 176  loss: 6.24235201\n",
      "epoch: 201  loss: 5.04176521\n",
      "epoch: 226  loss: 4.22815228\n",
      "epoch: 251  loss: 3.88593531\n",
      "epoch: 276  loss: 3.75551224\n",
      "epoch: 300  loss: 3.72141528\n",
      "\n",
      "Duration: 59 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a9413ef-da5f-40e0-ac0b-2b72bd462efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.569010734558105,\n",
       " 12.469820976257324,\n",
       " 12.374269485473633,\n",
       " 12.277074813842773,\n",
       " 12.184469223022461,\n",
       " 12.101001739501953,\n",
       " 12.022682189941406,\n",
       " 11.938425064086914,\n",
       " 11.857657432556152,\n",
       " 11.785173416137695,\n",
       " 11.707448959350586,\n",
       " 11.638782501220703,\n",
       " 11.573042869567871,\n",
       " 11.511761665344238,\n",
       " 11.454021453857422,\n",
       " 11.386719703674316,\n",
       " 11.334015846252441,\n",
       " 11.275562286376953,\n",
       " 11.232911109924316,\n",
       " 11.17303466796875,\n",
       " 11.126663208007812,\n",
       " 11.083915710449219,\n",
       " 11.038886070251465,\n",
       " 10.990408897399902,\n",
       " 10.949235916137695,\n",
       " 10.905743598937988,\n",
       " 10.878695487976074,\n",
       " 10.835139274597168,\n",
       " 10.79994010925293,\n",
       " 10.75894832611084,\n",
       " 10.723686218261719,\n",
       " 10.70061206817627,\n",
       " 10.656408309936523,\n",
       " 10.638839721679688,\n",
       " 10.603982925415039,\n",
       " 10.574305534362793,\n",
       " 10.542184829711914,\n",
       " 10.514717102050781,\n",
       " 10.497783660888672,\n",
       " 10.469453811645508,\n",
       " 10.45338249206543,\n",
       " 10.422211647033691,\n",
       " 10.405135154724121,\n",
       " 10.382951736450195,\n",
       " 10.352581024169922,\n",
       " 10.341711044311523,\n",
       " 10.303053855895996,\n",
       " 10.279218673706055,\n",
       " 10.256845474243164,\n",
       " 10.245404243469238,\n",
       " 10.229239463806152,\n",
       " 10.207669258117676,\n",
       " 10.192505836486816,\n",
       " 10.168551445007324,\n",
       " 10.141681671142578,\n",
       " 10.113982200622559,\n",
       " 10.10985279083252,\n",
       " 10.076553344726562,\n",
       " 10.064790725708008,\n",
       " 10.051811218261719,\n",
       " 10.026519775390625,\n",
       " 10.008362770080566,\n",
       " 9.99377155303955,\n",
       " 9.972418785095215,\n",
       " 9.958215713500977,\n",
       " 9.925248146057129,\n",
       " 9.907700538635254,\n",
       " 9.897664070129395,\n",
       " 9.883209228515625,\n",
       " 9.849777221679688,\n",
       " 9.84235954284668,\n",
       " 9.821257591247559,\n",
       " 9.803659439086914,\n",
       " 9.777823448181152,\n",
       " 9.75610065460205,\n",
       " 9.747282028198242,\n",
       " 9.726227760314941,\n",
       " 9.701435089111328,\n",
       " 9.673418998718262,\n",
       " 9.660139083862305,\n",
       " 9.637262344360352,\n",
       " 9.629251480102539,\n",
       " 9.602583885192871,\n",
       " 9.579503059387207,\n",
       " 9.55931568145752,\n",
       " 9.542810440063477,\n",
       " 9.519208908081055,\n",
       " 9.49477481842041,\n",
       " 9.478952407836914,\n",
       " 9.457052230834961,\n",
       " 9.428497314453125,\n",
       " 9.416125297546387,\n",
       " 9.391901016235352,\n",
       " 9.368788719177246,\n",
       " 9.342912673950195,\n",
       " 9.319165229797363,\n",
       " 9.303925514221191,\n",
       " 9.27180004119873,\n",
       " 9.249083518981934,\n",
       " 9.219829559326172,\n",
       " 9.197528839111328,\n",
       " 9.170201301574707,\n",
       " 9.144881248474121,\n",
       " 9.1127290725708,\n",
       " 9.081965446472168,\n",
       " 9.060541152954102,\n",
       " 9.036407470703125,\n",
       " 8.99478816986084,\n",
       " 8.97363567352295,\n",
       " 8.938825607299805,\n",
       " 8.908693313598633,\n",
       " 8.884637832641602,\n",
       " 8.84550666809082,\n",
       " 8.811623573303223,\n",
       " 8.785391807556152,\n",
       " 8.762884140014648,\n",
       " 8.74106216430664,\n",
       " 8.697635650634766,\n",
       " 8.677953720092773,\n",
       " 8.635374069213867,\n",
       " 8.605355262756348,\n",
       " 8.569194793701172,\n",
       " 8.544666290283203,\n",
       " 8.498074531555176,\n",
       " 8.462519645690918,\n",
       " 8.421018600463867,\n",
       " 8.3854398727417,\n",
       " 8.357341766357422,\n",
       " 8.31097412109375,\n",
       " 8.27746295928955,\n",
       " 8.245589256286621,\n",
       " 8.204231262207031,\n",
       " 8.17222785949707,\n",
       " 8.144810676574707,\n",
       " 8.091490745544434,\n",
       " 8.050237655639648,\n",
       " 8.016011238098145,\n",
       " 7.981790542602539,\n",
       " 7.935479164123535,\n",
       " 7.888457298278809,\n",
       " 7.845666408538818,\n",
       " 7.807738304138184,\n",
       " 7.774054050445557,\n",
       " 7.728402137756348,\n",
       " 7.672967910766602,\n",
       " 7.644078731536865,\n",
       " 7.592385292053223,\n",
       " 7.539387226104736,\n",
       " 7.523653030395508,\n",
       " 7.461852550506592,\n",
       " 7.405109882354736,\n",
       " 7.3784661293029785,\n",
       " 7.32625150680542,\n",
       " 7.291406154632568,\n",
       " 7.25551176071167,\n",
       " 7.190161228179932,\n",
       " 7.143523216247559,\n",
       " 7.120100021362305,\n",
       " 7.063459873199463,\n",
       " 7.006152153015137,\n",
       " 6.96413516998291,\n",
       " 6.927289009094238,\n",
       " 6.872645378112793,\n",
       " 6.81434965133667,\n",
       " 6.757428169250488,\n",
       " 6.733624458312988,\n",
       " 6.674008369445801,\n",
       " 6.624946594238281,\n",
       " 6.588464260101318,\n",
       " 6.539067268371582,\n",
       " 6.500260829925537,\n",
       " 6.442302227020264,\n",
       " 6.409218788146973,\n",
       " 6.336315155029297,\n",
       " 6.29565954208374,\n",
       " 6.24235200881958,\n",
       " 6.188272953033447,\n",
       " 6.1561808586120605,\n",
       " 6.0974040031433105,\n",
       " 6.036835193634033,\n",
       " 6.007076263427734,\n",
       " 5.958629131317139,\n",
       " 5.892805576324463,\n",
       " 5.851385116577148,\n",
       " 5.788130283355713,\n",
       " 5.749119281768799,\n",
       " 5.7159318923950195,\n",
       " 5.643160343170166,\n",
       " 5.599259853363037,\n",
       " 5.570268154144287,\n",
       " 5.509848594665527,\n",
       " 5.465324401855469,\n",
       " 5.439640045166016,\n",
       " 5.382305145263672,\n",
       " 5.313708305358887,\n",
       " 5.276814937591553,\n",
       " 5.233089923858643,\n",
       " 5.1687211990356445,\n",
       " 5.141589641571045,\n",
       " 5.088241100311279,\n",
       " 5.041765213012695,\n",
       " 5.016592502593994,\n",
       " 4.977629661560059,\n",
       " 4.914508819580078,\n",
       " 4.87498664855957,\n",
       " 4.8736772537231445,\n",
       " 4.822209358215332,\n",
       " 4.790142059326172,\n",
       " 4.6949262619018555,\n",
       " 4.704598426818848,\n",
       " 4.651026248931885,\n",
       " 4.637640953063965,\n",
       " 4.571183204650879,\n",
       " 4.533743381500244,\n",
       " 4.540770530700684,\n",
       " 4.485847473144531,\n",
       " 4.436001300811768,\n",
       " 4.408639907836914,\n",
       " 4.391515731811523,\n",
       " 4.346212863922119,\n",
       " 4.357034206390381,\n",
       " 4.280101299285889,\n",
       " 4.276650905609131,\n",
       " 4.223027229309082,\n",
       " 4.232590675354004,\n",
       " 4.228152275085449,\n",
       " 4.20920467376709,\n",
       " 4.178305625915527,\n",
       " 4.138148307800293,\n",
       " 4.115368366241455,\n",
       " 4.105450630187988,\n",
       " 4.084742069244385,\n",
       " 4.0904541015625,\n",
       " 4.046388626098633,\n",
       " 4.027591705322266,\n",
       " 4.0171990394592285,\n",
       " 4.012048721313477,\n",
       " 3.997802972793579,\n",
       " 3.9922878742218018,\n",
       " 3.9714701175689697,\n",
       " 3.9286305904388428,\n",
       " 3.9380006790161133,\n",
       " 3.922767162322998,\n",
       " 3.9244892597198486,\n",
       " 3.903297185897827,\n",
       " 3.9156250953674316,\n",
       " 3.949337959289551,\n",
       " 3.861433744430542,\n",
       " 3.8957197666168213,\n",
       " 3.890702724456787,\n",
       " 3.8859353065490723,\n",
       " 3.8669774532318115,\n",
       " 3.8479630947113037,\n",
       " 3.857088088989258,\n",
       " 3.8478214740753174,\n",
       " 3.80936598777771,\n",
       " 3.816761016845703,\n",
       " 3.7907462120056152,\n",
       " 3.8345611095428467,\n",
       " 3.8581926822662354,\n",
       " 3.7930893898010254,\n",
       " 3.826340436935425,\n",
       " 3.7963056564331055,\n",
       " 3.80061411857605,\n",
       " 3.7825305461883545,\n",
       " 3.811471939086914,\n",
       " 3.766477108001709,\n",
       " 3.7884390354156494,\n",
       " 3.8064332008361816,\n",
       " 3.7626006603240967,\n",
       " 3.790043354034424,\n",
       " 3.8295037746429443,\n",
       " 3.7541050910949707,\n",
       " 3.7700276374816895,\n",
       " 3.768301486968994,\n",
       " 3.755512237548828,\n",
       " 3.753277063369751,\n",
       " 3.759916305541992,\n",
       " 3.769599676132202,\n",
       " 3.7445149421691895,\n",
       " 3.7506184577941895,\n",
       " 3.737199068069458,\n",
       " 3.7577342987060547,\n",
       " 3.739793300628662,\n",
       " 3.7169015407562256,\n",
       " 3.7349345684051514,\n",
       " 3.7500784397125244,\n",
       " 3.7320971488952637,\n",
       " 3.734558582305908,\n",
       " 3.7087783813476562,\n",
       " 3.730264186859131,\n",
       " 3.703781843185425,\n",
       " 3.7336652278900146,\n",
       " 3.708059310913086,\n",
       " 3.7159345149993896,\n",
       " 3.702331781387329,\n",
       " 3.682246685028076,\n",
       " 3.70500111579895,\n",
       " 3.722476005554199,\n",
       " 3.7214152812957764]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [loss.item() for loss in losses]\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9edae049-c667-4414-9ee7-4faa130e4504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), values)\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5822f7-78a6-42b4-b939-7ed2f50d1946",
   "metadata": {},
   "source": [
    "## Validate the model\n",
    "Here we want to run the entire test set through the model, and compare it to the known labels.<br>\n",
    "For this step we don't want to update weights and biases, so we set <tt>torch.no_grad()</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f08753f4-877c-40cc-8c25-aab2fceffb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.62440896\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8df206e7-aa8d-42f2-8163-c4fd9db2f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1.   4.2268   2.9000   1.3268\n",
      " 2.  14.4239   5.7000   8.7239\n",
      " 3.   7.0660   7.7000   0.6340\n",
      " 4.  14.4481  12.5000   1.9481\n",
      " 5.   5.7160   4.1000   1.6160\n",
      " 6.   5.5413   5.3000   0.2413\n",
      " 7.   4.4783   3.7000   0.7783\n",
      " 8.  19.9968  14.5000   5.4968\n",
      " 9.   9.5426   5.7000   3.8426\n",
      "10.  12.6801  10.1000   2.5801\n",
      "11.   7.7337   4.5000   3.2337\n",
      "12.   1.1452   6.1000   4.9548\n",
      "13.   6.4696   6.9000   0.4304\n",
      "14.  10.7891  14.1000   3.3109\n",
      "15.   4.9896   4.5000   0.4896\n",
      "16.  31.4864  34.1000   2.6136\n",
      "17.   1.0608  12.5000  11.4392\n",
      "18.   5.9803   4.1000   1.8803\n",
      "19.   7.0544   8.5000   1.4456\n",
      "20.   3.8917   5.3000   1.4083\n",
      "21.  14.6576  11.3000   3.3576\n",
      "22.   9.5653  10.5000   0.9347\n",
      "23.  17.4824  15.3000   2.1824\n",
      "24.  16.6995  14.9000   1.7995\n",
      "25.  46.0782  49.5700   3.4918\n",
      "26.   1.9759   5.3000   3.3241\n",
      "27.   4.7248   3.7000   1.0248\n",
      "28.   4.7162   6.5000   1.7838\n",
      "29.  14.5877  14.1000   0.4877\n",
      "30.   6.6218   4.9000   1.7218\n",
      "31.   4.5907   3.7000   0.8907\n",
      "32.  32.1879  38.6700   6.4821\n",
      "33.  15.0209  12.5000   2.5209\n",
      "34.  13.5852  16.5000   2.9148\n",
      "35.   3.2016   5.7000   2.4984\n",
      "36.   8.6190   8.9000   0.2810\n",
      "37.  20.0516  22.1000   2.0484\n",
      "38.   8.6112  12.1000   3.4888\n",
      "39.   7.0125  10.1000   3.0875\n",
      "40.   4.2043   3.3000   0.9043\n",
      "41.  12.5728   8.5000   4.0728\n",
      "42.   9.9477   8.1000   1.8477\n",
      "43.   9.5671  14.5000   4.9329\n",
      "44.   7.4494   4.9000   2.5494\n",
      "45.   4.6173   8.5000   3.8827\n",
      "46.  11.1672  12.1000   0.9328\n",
      "47.  22.5895  23.7000   1.1105\n",
      "48.   3.2461   3.7000   0.4539\n",
      "49.   7.3618   9.3000   1.9382\n",
      "50.   9.0257   8.1000   0.9257\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(50):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64e60b64-c8e2-48c2-89fa-1db6a0e011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b0481-344f-4dab-b1ac-add5072119d1",
   "metadata": {},
   "source": [
    "## Loading a saved model (starting from scratch)\n",
    "We can load the trained weights and biases from a saved model. If we've just opened the notebook, we'll have to run standard imports and function definitions. To demonstrate, restart the kernel before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f347da94-3d70-4a07-8c3f-5e805f9d0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21c80dc2-16f6-4b7c-9199-65b4cc515c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "797e7068-1162-4995-9562-54b6b0b0d602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('TaxiFareRegrModel.pt'));\n",
    "model2.eval() # be sure to run this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5aabc7d7-d22a-475a-85bf-3fe8cfb23315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(mdl): # pass in the name of the new model\n",
    "    # INPUT NEW DATA\n",
    "    plat = float(input('What is the pickup latitude?  '))\n",
    "    plong = float(input('What is the pickup longitude? '))\n",
    "    dlat = float(input('What is the dropoff latitude?  '))\n",
    "    dlong = float(input('What is the dropoff longitude? '))\n",
    "    psngr = int(input('How many passengers? '))\n",
    "    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n",
    "    \n",
    "    # PREPROCESS THE DATA\n",
    "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
    "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
    "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
    "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
    "                                        'dropoff_latitude', 'dropoff_longitude')\n",
    "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
    "    \n",
    "    # We can skip the .astype(category) step since our fields are small,\n",
    "    # and encode them right away\n",
    "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
    "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
    "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
    "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
    "    # CREATE CAT AND CONT TENSORS\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
    "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
    "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
    "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
    "    \n",
    "    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(xcats, xconts)\n",
    "    print(f'\\nThe predicted fare amount is ${z.item():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c069ef86-55b1-4885-9309-672e092aff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the pickup latitude?   40.5\n",
      "What is the pickup longitude?  -73.9\n",
      "What is the dropoff latitude?   40.52\n",
      "What is the dropoff longitude?  -73.92\n",
      "How many passengers?  2\n",
      "What is the pickup date and time?\n",
      "Format as YYYY-MM-DD HH:MM:SS      2010-04-15 16:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted fare amount is $15.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asalmon\\AppData\\Local\\Temp\\ipykernel_5000\\641314667.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n"
     ]
    }
   ],
   "source": [
    "z = test_data(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bbafed-692b-4df7-b8fa-4ef0f7465e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
